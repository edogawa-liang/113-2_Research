import os
import numpy as np
import torch
import matplotlib.pyplot as plt
import pandas as pd

# 核心子圖包含整個節點
# 處理PyG支援的可解釋方法

class ExplainerEdgeSelector:
    """
    Select important edges using explanations generated by an explainer model.
    """

    def __init__(self, data, base_dir, explainer_name, dataset_name, selected_nodes, top_k_percent, feature_type, device, top_k_percent_feat, use_feature_to_node):
        """
        :param base_dir: The base directory where experiment results are stored.
        :param explainer_name: Name of the explainer model (e.g., 'GNNExplainer').
        :param dataset_name: Name of the dataset (e.g., 'CiteSeer').
        :param top_k_percent: The percentage of top important edges to select.
        """
        
        self.data = data.to(device)
        self.selected_nodes = selected_nodes  # 選擇的節點indices
        self.base_path = os.path.join(base_dir, explainer_name, dataset_name)
        self.edge_masks = []  # 存放所有 edge_mask
        self.edge_aggregated = None  # 平均 edge_mask
        self.top_k_percent = top_k_percent
        self.top_k_percent_feat = top_k_percent_feat
        self.feature_type = feature_type
        self.device = device
        self.feature_scores = None
        self.combined_node_mask = None 
        self.use_feature_to_node = use_feature_to_node

    def load_data(self, split_id):
        """
        根據每個 model 的 node_record.csv 中某欄位的 one-hot 選擇節點，
        並從 share_nodes/ 中載入 edge_mask 後加總。
        """
        self.edge_masks = []
        self.node_masks = []

        exp_dir = os.path.join(self.base_path, f"{split_id}_GCN2Classifier")

        if not os.path.exists(exp_dir):
            print(f"Warning: explanation folder not found in {exp_dir}")

        for node_id in self.selected_nodes:
            file_path = os.path.join(exp_dir, f"node_{node_id}.npz")

            if not os.path.exists(file_path):
                raise FileNotFoundError(f"File {file_path} does not exist. Please check the selected_nodes list and explanation folder.")

            exp_data = np.load(file_path, allow_pickle=True)
            edge_mask = exp_data.get("edge_mask", None)
            if edge_mask is not None:
                self.edge_masks.append(edge_mask)

            # 有使用 feature 挑選子圖，且沒有 feature to node 時 (要直接用node_mask)
            if not self.use_feature_to_node and self.top_k_percent_feat != 0:
                node_mask = exp_data.get("node_mask", None)
                if node_mask is not None:
                    self.node_masks.append(node_mask)

        if self.edge_masks:
            # 將同一解釋子圖內不同node的重要度相加，並把不同模型的解釋子圖的重要度也相加
            self.edge_aggregated = np.sum(self.edge_masks, axis=0) 
            print(f"Number of edges picked in the subgraph: {np.count_nonzero(self.edge_aggregated)}")
        
        if self.node_masks:
            print("use node_mask for choosing subgraph")
            node_masks = np.stack(self.node_masks).astype(np.float64)
            print(f"Stacked node_masks shape: {node_masks.shape}")
            self.combined_node_mask = node_masks.sum(axis=0) # shape: (num_nodes, num_features,)
            self.feature_scores = self.combined_node_mask.sum(axis=0)  # shape: (num_features,)
            # print(f"Loaded node-wise feature importance, shape: {self.feature_scores.shape}")

        elif not self.use_feature_to_node and self.top_k_percent_feat != 0:
            print("Warning: No node_mask found in any .npz file.")

    def select_edges(self):
        """
        Selects important edges and optionally returns the feature IDs associated with selected feature edges.

        :return:
            - selected_edge_indices (Tensor)
            - selected_feat_ids (List[int]) if return_feat_ids=True, else None
        """
        if self.edge_aggregated is None:
            raise ValueError("No edge importance data available. Run load_data() first.")

        # 讀 mask
        node_node_mask_np = self.data.node_node_mask.cpu().numpy()
        node_feat_mask_np = self.data.node_feat_mask.cpu().numpy()
        
        # 數量
        num_ori_edges = node_node_mask_np.sum()
        num_feat_edges = node_feat_mask_np.sum()

        # 沒有特徵邊
        if num_feat_edges == 0 and not self.use_feature_to_node:
            print("No feature edges found. Selecting top-k% from original edges only.")
            k = int(num_ori_edges * self.top_k_percent)
            #  -0 在 Python 中等於 0，但 slice 中會被當作 [:] → 取全部！
            if k == 0:
                top_k_edges = np.array([], dtype=int)
            else:
                top_k_edges = np.argsort(self.edge_aggregated[node_node_mask_np])[-k:]
            selected_orig_edge_indices = np.where(node_node_mask_np)[0][top_k_edges]
            print(f"Selected {len(selected_orig_edge_indices)} original edges.")

            return torch.tensor(selected_orig_edge_indices, dtype=torch.long, device=self.device), []

        # 有特徵邊
        else:
            k_orig = int(num_ori_edges * self.top_k_percent)
            if self.feature_type == "categorical":
                k_feat = int(num_feat_edges * self.top_k_percent_feat)
            elif self.feature_type == "continuous":
                k_feat = int(num_feat_edges * self.top_k_percent_feat)
                    
            # === 處理 node-node 選擇 === #
            if k_orig == 0:
                top_orig = np.array([], dtype=int)
            else:
                top_orig = np.argsort(self.edge_aggregated[node_node_mask_np])[-k_orig:]

            # === 處理 node-feature 選擇 === #
            if k_feat == 0:
                top_feat = np.array([], dtype=int)
            else:
                top_feat = np.argsort(self.edge_aggregated[node_feat_mask_np])[-k_feat:]
            
            # 對應回全域 index
            selected_orig_edge_indices = np.where(node_node_mask_np)[0][top_orig]
            selected_feat_edge_indices = np.where(node_feat_mask_np)[0][top_feat]

            selected_idx = np.concatenate([selected_orig_edge_indices, selected_feat_edge_indices])
            selected_idx_tensor = torch.tensor(selected_idx, dtype=torch.long, device=self.device)

            print(f"Selected {len(selected_idx_tensor)} edges: {len(selected_orig_edge_indices)} original and {len(selected_feat_edge_indices)} feature edges.")

            is_feature_node_np = self.data.is_feature_node.cpu().numpy()
            ori_num_features = is_feature_node_np.sum()

            # Rel idx in feature edges
            rel_idx = np.arange(num_feat_edges)[top_feat]
            pair_idx = rel_idx // 2
            selected_feat_ids = pair_idx % ori_num_features # feat_id 每次從 0 到 num_features-1 走一輪。

            # 回傳子圖的邊 (含原始邊和特徵邊) 及 這次解釋 subgraph 中 importance 最高的 feature edge，對應的 feature 是哪些
            return selected_idx_tensor, selected_feat_ids 

        

    # 當需要使用解釋子圖本身的node_mask找特徵時
    def select_node_features(self, same_feat=True):
        if self.feature_scores is None:
            raise ValueError("No feature importance available. Run load_data() first with appropriate flags.")

        num_features = len(self.feature_scores)
        k = int(num_features * self.top_k_percent_feat)

        # 直接從 data 裡抓出原始節點數量
        is_original_node_np = self.data.is_original_node.cpu().numpy()
        num_ori_nodes = is_original_node_np.sum()
        
        # 若 k = 0，直接回傳全 0 mask
        if k == 0:
            print(f"[Warning] top_k_percent_feat is 0 → no features selected.")
            return torch.zeros((num_ori_nodes, num_features), dtype=torch.float32, device=self.device)

        if same_feat:
            # 所有節點移除相同特徵
            selected_feat = np.argsort(self.feature_scores)[-k:]
            print(f"[same_feat=True] Selected top {k} important features for all {num_ori_nodes} nodes.")
            
            mask = torch.zeros((num_ori_nodes, num_features), dtype=torch.float32, device=self.device)
            mask[:, selected_feat] = 1.0
            return mask

        else:
            if self.combined_node_mask is None:
                raise ValueError("No per-node node_mask available for per-node feature selection.")

            print(f"[same_feat=False] Selecting top {k} features per node based on individual node_masks.")
            mask = torch.zeros((num_ori_nodes, num_features), dtype=torch.float32, device=self.device)

            for i, node_mask in enumerate(self.combined_node_mask):
                if len(node_mask) != num_features:
                    raise ValueError(f"Node mask length mismatch at index {i}: {len(node_mask)} vs {num_features}")
                topk = np.argsort(node_mask)[-k:]
                mask[i, topk] = 1.0 # 重要的特徵mask給1


            return mask


    def plot_edge_distribution(self):
        """
        Plots and saves the distribution of edge importance scores.
        """
        if self.edge_aggregated is None:
            raise ValueError("No edge values available. Run load_data() first.")

        save_path = os.path.join(self.base_path, "edge_importance_distribution.png")

        plt.figure(figsize=(8, 6))
        plt.hist(self.edge_aggregated, bins=50, color="blue", alpha=0.7, edgecolor="black")
        plt.xlabel("Edge Importance Score")
        plt.ylabel("Frequency")
        plt.title("Edge Importance Score Distribution")
        plt.grid(True)

        plt.savefig(save_path)
        print(f"Edge importance distribution saved to {save_path}")
