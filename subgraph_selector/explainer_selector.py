import os
import numpy as np
import torch
import matplotlib.pyplot as plt
import pandas as pd

# 核心子圖包含整個節點
# 處理PyG支援的可解釋方法

class ExplainerEdgeSelector:
    """
    Select important edges using explanations generated by an explainer model.
    """

    def __init__(self, data, base_dir, explainer_name, dataset_name, node_choose, top_k_percent, feature_type, device, top_k_percent_feat, use_feature_to_node):
        """
        :param base_dir: The base directory where experiment results are stored.
        :param explainer_name: Name of the explainer model (e.g., 'GNNExplainer').
        :param dataset_name: Name of the dataset (e.g., 'CiteSeer').
        :param node_choose: The name of the experiment folder under the dataset (default: 'random').
        :param top_k_percent: The percentage of top important edges to select.
        """
        
        self.data = data.to(device)
        self.base_path = os.path.join(base_dir, explainer_name, dataset_name)
        self.sub_dirs = sorted([d for d in os.listdir(self.base_path) if d.endswith("GCN2Classifier")]) # GCN2Regressor
        self.edge_masks = []  # 存放所有 edge_mask
        self.edge_aggregated = None  # 平均 edge_mask
        self.top_k_percent = top_k_percent
        self.top_k_percent_feat = top_k_percent_feat
        self.feature_type = feature_type
        self.device = device
        self.node_choose = node_choose
        self.feature_scores = None
        self.combined_node_mask = None 
        self.use_feature_to_node = use_feature_to_node
        self.node_count = 0

    def load_data(self):
        """
        根據每個 model 的 node_record.csv 中某欄位的 one-hot 選擇節點，
        並從 share_nodes/ 中載入 edge_mask 後加總。
        """
        self.edge_masks = []
        self.node_masks = []

        for sub_dir in self.sub_dirs:  # ex: '1_GCN2Classifier'
            model_dir = os.path.join(self.base_path, sub_dir)
            share_node_dir = os.path.join(model_dir, "share_nodes")
            csv_path = os.path.join(model_dir, "node_record.csv")

            if not os.path.exists(csv_path):
                print(f"Warning: node_record.csv not found in {model_dir}")
                continue

            df = pd.read_csv(csv_path)
            if self.node_choose not in df.columns:
                print(f"Warning: column '{self.node_choose}' not found in {csv_path}")
                continue

            selected_nodes = df[df[self.node_choose] == 1]["Node"].tolist()

            # 設定 node 數量（僅需計算一次）
            if self.node_count == 0:
                self.node_count = len(selected_nodes) 

            for node_id in selected_nodes:
                file_path = os.path.join(share_node_dir, f"node_{node_id}.npz")
                if not os.path.exists(file_path):
                    print(f"File {file_path} does not exist. Warn!!!!.")
                    continue

                data = np.load(file_path, allow_pickle=True)
                edge_mask = data.get("edge_mask", None)
                if edge_mask is not None:
                    self.edge_masks.append(edge_mask)

                # 有使用 feature 挑選子圖，且沒有 feature to node 時 (要直接用node_mask)
                if not self.use_feature_to_node and self.top_k_percent_feat != 0:
                    node_mask = data.get("node_mask", None)
                    if node_mask is not None:
                        # print("use node_mask for choosing subgraph")
                        self.node_masks.append(node_mask)

        if self.edge_masks:
            # 將同一解釋子圖內不同node的重要度相加，並把不同模型的解釋子圖的重要度也相加
            self.edge_aggregated = np.sum(self.edge_masks, axis=0) 
            print(f"Number of nodes selected: {self.node_count}")
            print(f"Number of edges picked in the subgraph: {np.count_nonzero(self.edge_aggregated)}")
        
        if self.node_masks:
            # node_masks = np.stack(node_masks)
            print("use node_mask for choosing subgraph")
            node_masks = np.stack(self.node_masks).astype(np.float64)
            print(f"Stacked node_masks shape: {node_masks.shape}")
            self.combined_node_mask = node_masks.sum(axis=0) # shape: (num_nodes, num_features,)
            self.feature_scores = self.combined_node_mask.sum(axis=0)  # shape: (num_features,)
            # print(f"Loaded node-wise feature importance, shape: {self.feature_scores.shape}")
        elif not self.use_feature_to_node and self.top_k_percent_feat != 0:
            print("Warning: No node_mask found in any .npz file.")



    def select_edges(self, num_ori_edges, num_ori_nodes, ori_num_features=None, return_feat_ids=True):
        """
        Selects important edges and optionally returns the feature IDs associated with selected feature edges.

        :param num_ori_edges: Number of original node-node edges
        :param num_ori_nodes: Number of original (non-feature) nodes
        :param ori_num_features: Required if return_feat_ids is True
        :param return_feat_ids: If True, returns list of feature IDs for selected feature edges
        :return:
            - selected_edge_indices (Tensor)
            - selected_feat_ids (List[int]) if return_feat_ids=True, else None
        """
        if self.edge_aggregated is None:
            raise ValueError("No edge importance data available. Run load_data() first.")

        num_total = len(self.edge_aggregated) # 可能是原始邊 也可能是包含特徵的邊
        num_feat = num_total - num_ori_edges
        print(f"Total edges: {num_total}, Original edges: {num_ori_edges}, Feature edges: {num_feat}")

        # 沒有特徵邊
        if num_feat == 0 and not self.use_feature_to_node: # 雙重驗證
            print("No feature edges found. Selecting top-k% from original edges only.")
            k = int(num_total * self.top_k_percent)
            top_k_edges = np.argsort(self.edge_aggregated)[-k:]
            return torch.tensor(top_k_edges, dtype=torch.long, device=self.device), [] # 只有被挑中的原始節點邊

        # 有特徵邊
        elif num_feat > 0:
            k_orig = int(num_ori_edges * self.top_k_percent) # 原始邊的 top-k%
            if self.feature_type == "categorical":
                k_feat = int(num_feat * self.top_k_percent_feat)
            elif self.feature_type == "continuous":
                k_feat = int(ori_num_features * self.top_k_percent_feat * num_ori_nodes) # 特徵數量 × top_k_percent_feat × 節點數 (類別型的話會超過實際的特徵邊數..)

            top_orig = np.argsort(self.edge_aggregated[:num_ori_edges])[-k_orig:]
            top_feat = np.argsort(self.edge_aggregated[num_ori_edges:])[-k_feat:] + num_ori_edges

            selected_idx = np.concatenate([top_orig, top_feat])
            selected_idx_tensor = torch.tensor(selected_idx, dtype=torch.long, device=self.device)
            print(f"Selected {len(selected_idx_tensor)} edges: {len(top_orig)} original and {len(top_feat)} feature edges.")

            if return_feat_ids:
                if ori_num_features is None:
                    raise ValueError("num_features must be provided when return_feat_ids=True.")

                selected_feat_ids = []
                for i in top_feat:
                    rel_idx = i - num_ori_edges        # 移除 offset
                    pair_idx = rel_idx // 2            # 每 (node, feat) 雙向邊占兩格
                    feat_id = pair_idx % ori_num_features  # 抽出對應的 feature id
                    selected_feat_ids.append(feat_id)

                return selected_idx_tensor, selected_feat_ids

            return selected_idx_tensor, []
        else:
            raise ValueError("Edge selection failed: cannot determine how to separate original and feature edges.")

        
    # 當需要使用解釋子圖本身的node_mask找特徵時
    def select_node_features(self, num_ori_nodes, same_feat=True):
        if self.feature_scores is None:
            raise ValueError("No feature importance available. Run load_data() first with appropriate flags.")

        num_features = len(self.feature_scores)
        # print(f"Number of features: {num_features}")
        # print("shape of node_mask:", len(self.node_masks))
        k = int(num_features * self.top_k_percent_feat)

        if same_feat:
            # 所有節點移除相同特徵
            selected_feat = np.argsort(self.feature_scores)[-k:]
            print(f"[same_feat=True] Selected top {k} important features for all {num_ori_nodes} nodes.")
            
            mask = torch.zeros((num_ori_nodes, num_features), dtype=torch.float32, device=self.device)
            mask[:, selected_feat] = 1.0
            return mask

        else:
            if self.combined_node_mask is None:
                raise ValueError("No per-node node_mask available for per-node feature selection.")

            print(f"[same_feat=False] Selecting top {k} features per node based on individual node_masks.")
            mask = torch.zeros((num_ori_nodes, num_features), dtype=torch.float32, device=self.device)

            for i, node_mask in enumerate(self.combined_node_mask):
                if len(node_mask) != num_features:
                    raise ValueError(f"Node mask length mismatch at index {i}: {len(node_mask)} vs {num_features}")
                topk = np.argsort(node_mask)[-k:]
                mask[i, topk] = 1.0 # 重要的特徵mask給1


            return mask


    def plot_edge_distribution(self):
        """
        Plots and saves the distribution of edge importance scores.
        """
        if self.edge_aggregated is None:
            raise ValueError("No edge values available. Run load_data() first.")

        save_path = os.path.join(self.base_path, "edge_importance_distribution.png")

        plt.figure(figsize=(8, 6))
        plt.hist(self.edge_aggregated, bins=50, color="blue", alpha=0.7, edgecolor="black")
        plt.xlabel("Edge Importance Score")
        plt.ylabel("Frequency")
        plt.title("Edge Importance Score Distribution")
        plt.grid(True)

        plt.savefig(save_path)
        print(f"Edge importance distribution saved to {save_path}")

    def get_node_count(self):
        return self.node_count

    def get_edge_count(self):
        return np.count_nonzero(self.edge_aggregated)