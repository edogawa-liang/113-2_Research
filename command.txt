# 1. Original node classification
------------------------------------------------------------
python training_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode original --note basic_node_cls --use_original_label true
python training_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode original --note basic_node_cls --use_original_label true
python training_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode original --note basic_node_cls --use_original_label true
python training_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode original --note basic_node_cls --use_original_label true
python training_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode original --note basic_node_cls --use_original_label true


# 2. Train GNN model (node classification) after random subgraph selection
------------------------------------------------------------
python train_remaining_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode baselineResult --note basic_node_cls --selector_type random --fraction 0.1
python train_remaining_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode baselineResult --note basic_node_cls --selector_type random --fraction 0.1
python train_remaining_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode baselineResult --note basic_node_cls --selector_type random --fraction 0.1
python train_remaining_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode baselineResult --note basic_node_cls --selector_type random --fraction 0.1
python train_remaining_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode baselineResult --note basic_node_cls --selector_type random --fraction 0.1


# 3. using PCA for for feature selection and Train base GNN model (node regression) for explainer (multi features for y) 
------------------------------------------------------------
python training_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode stage1 --note basic_node_reg --use_original_label false
python training_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode stage1 --note basic_node_reg --use_original_label false
python training_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode stage1 --note basic_node_reg --use_original_label false
python training_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode stage1 --note basic_node_reg --use_original_label false
python training_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode stage1 --note basic_node_reg --use_original_label false


# 4. Generate GNNExplainer explainable subgraph from random nodes (base on node regression model from #3)
------------------------------------------------------------
python stage2_expsubg.py --dataset GitHub  --choose_nodes random --node_ratio 0.01
python stage2_expsubg.py --dataset FacebookPagePage  --choose_nodes random --node_ratio 0.01
python stage2_expsubg.py --dataset Cora  --choose_nodes random --node_ratio 0.01
python stage2_expsubg.py --dataset CiteSeer  --choose_nodes random --node_ratio 0.01
python stage2_expsubg.py --dataset PubMed  --choose_nodes random --node_ratio 0.01

python stage2_expsubg.py --dataset Cora  --choose_nodes random --node_ratio 0.05 --run_mode stage2_node_ratio_0.05
python stage2_expsubg.py --dataset CiteSeer  --choose_nodes random --node_ratio 0.05 --run_mode stage2_node_ratio_0.05
python stage2_expsubg.py --dataset PubMed  --choose_nodes random --node_ratio 0.05 --run_mode stage2_node_ratio_0.05


# 5. Train GNN model (node classification) after explainable subgraph selection (base on #4)
------------------------------------------------------------
python train_remaining_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer --selector_type explainer --fraction 0.1
python train_remaining_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer --selector_type explainer --fraction 0.1
python train_remaining_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer --selector_type explainer --fraction 0.1
python train_remaining_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer --selector_type explainer --fraction 0.1
python train_remaining_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer --selector_type explainer --fraction 0.1

python train_remaining_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05
python train_remaining_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05
python train_remaining_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05


# 6. Generate GNNExplainer subgraph from Top PageRank nodes (base on node regression model from #3)
# 跑完
------------------------------------------------------------
python stage2_expsubg.py --dataset GitHub  --choose_nodes top_pagerank --node_ratio 0.01 --run_mode stage2_node_ratio_0.01 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset FacebookPagePage  --choose_nodes top_pagerank --node_ratio 0.01 --run_mode stage2_node_ratio_0.01 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset Cora  --choose_nodes top_pagerank --node_ratio 0.05 --run_mode stage2_node_ratio_0.05 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset CiteSeer  --choose_nodes top_pagerank --node_ratio 0.05 --run_mode stage2_node_ratio_0.05 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset PubMed  --choose_nodes top_pagerank --node_ratio 0.05 --run_mode stage2_node_ratio_0.05 --explainer_type GNNExplainer


# 7. Generate Dummy explainable subgraph from random nodes (base on node regression model from #3)
# 跑完 (刪掉了 太佔空間)
------------------------------------------------------------
python stage2_expsubg.py --dataset GitHub  --choose_nodes random --node_ratio 0.01 --run_mode stage2_node_ratio_0.01 --explainer_type DummyExplainer
python stage2_expsubg.py --dataset FacebookPagePage  --choose_nodes random --node_ratio 0.01 --run_mode stage2_node_ratio_0.01 --explainer_type DummyExplainer
python stage2_expsubg.py --dataset Cora  --choose_nodes random --node_ratio 0.05 --run_mode stage2_node_ratio_0.05 --explainer_type DummyExplainer
python stage2_expsubg.py --dataset CiteSeer  --choose_nodes random --node_ratio 0.05 --run_mode stage2_node_ratio_0.05 --explainer_type DummyExplainer
python stage2_expsubg.py --dataset PubMed  --choose_nodes random --node_ratio 0.05 --run_mode stage2_node_ratio_0.05 --explainer_type DummyExplainer


# 8. Generate Dummy explainable subgraph from Top PageRank nodes (base on node regression model from #3)
# 跑完 (刪掉了 太佔空間)
------------------------------------------------------------
python stage2_expsubg.py --dataset GitHub  --choose_nodes top_pagerank --node_ratio 0.01 --run_mode stage2_node_ratio_0.01 --explainer_type DummyExplainer
python stage2_expsubg.py --dataset FacebookPagePage  --choose_nodes top_pagerank --node_ratio 0.01 --run_mode stage2_node_ratio_0.01 --explainer_type DummyExplainer
python stage2_expsubg.py --dataset Cora  --choose_nodes top_pagerank --node_ratio 0.05 --run_mode stage2_node_ratio_0.05 --explainer_type DummyExplainer
python stage2_expsubg.py --dataset CiteSeer  --choose_nodes top_pagerank --node_ratio 0.05 --run_mode stage2_node_ratio_0.05 --explainer_type DummyExplainer
python stage2_expsubg.py --dataset PubMed  --choose_nodes top_pagerank --node_ratio 0.05 --run_mode stage2_node_ratio_0.05 --explainer_type DummyExplainer


# 9. Train GNN model (node classification) after GNNExplainer from PageRank nodes selection (base on #6)
# 跑完
------------------------------------------------------------
python train_remaining_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.01 --explainer_name GNNExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.01 --explainer_name GNNExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05 --explainer_name GNNExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05 --explainer_name GNNExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_GNNExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05 --explainer_name GNNExplainer --node_choose top_pagerank


# 10. Train GNN model (node classification) after DummyExplainer from random nodes selection (base on #7)
# 跑完
------------------------------------------------------------
python train_remaining_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_DummyExplainer --note remove_edge_from_DummyExplainer_random --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.01 --explainer_name DummyExplainer --node_choose random
python train_remaining_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_DummyExplainer --note remove_edge_from_DummyExplainer_random --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.01 --explainer_name DummyExplainer --node_choose random
python train_remaining_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_DummyExplainer --note remove_edge_from_DummyExplainer_random --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05 --explainer_name DummyExplainer --node_choose random
python train_remaining_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_DummyExplainer --note remove_edge_from_DummyExplainer_random --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05 --explainer_name DummyExplainer --node_choose random
python train_remaining_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_DummyExplainer --note remove_edge_from_DummyExplainer_random --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05 --explainer_name DummyExplainer --node_choose random


# 11. Train GNN model (node classification) after DummyExplainer from Top PageRank nodes selection (base on #8)
# 跑完
------------------------------------------------------------

python train_remaining_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_DummyExplainer --note remove_edge_from_DummyExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.01 --explainer_name DummyExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_DummyExplainer --note remove_edge_from_DummyExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.01 --explainer_name DummyExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_DummyExplainer --note remove_edge_from_DummyExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05 --explainer_name DummyExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_DummyExplainer --note remove_edge_from_DummyExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05 --explainer_name DummyExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_DummyExplainer --note remove_edge_from_DummyExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_node_ratio_0.05 --explainer_name DummyExplainer --node_choose top_pagerank



# 12 Using Tree(Random Forest) for feature selection and Train base GNN model (node regression) for explainer (multi features for y) 
# 跑完
------------------------------------------------------------
python training_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode stage1_tree --note node_reg_tree --use_original_label false --feature_selection_method tree --top_tree_features 6
python training_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode stage1_tree --note node_reg_tree --use_original_label false --feature_selection_method tree --top_tree_features 6
python training_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode stage1_tree --note node_reg_tree --use_original_label false --feature_selection_method tree --top_tree_features 6
python training_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode stage1_tree --note node_reg_tree --use_original_label false --feature_selection_method tree --top_tree_features 6
python training_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode stage1_tree --note node_reg_tree --use_original_label false --feature_selection_method tree --top_tree_features 6


# 13. Generate GNNExplainer explainable subgraph from Top PageRank nodes Tree(base on node regression model from #12)
# 跑完 (PubMed 沒跑完)
------------------------------------------------------------
python stage2_expsubg.py --dataset GitHub  --choose_nodes top_pagerank --node_ratio 0.01 --run_mode stage2_tree_node_ratio_0.01 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset FacebookPagePage  --choose_nodes top_pagerank --node_ratio 0.01 --run_mode stage2_tree_node_ratio_0.01 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset Cora  --choose_nodes top_pagerank --node_ratio 0.05 --run_mode stage2_tree_node_ratio_0.05 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset CiteSeer  --choose_nodes top_pagerank --node_ratio 0.05 --run_mode stage2_tree_node_ratio_0.05 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset PubMed  --choose_nodes top_pagerank --node_ratio 0.05 --run_mode stage2_tree_node_ratio_0.05 --explainer_type GNNExplainer


# 14. Train GNN model (node classification) after Tree + GNNExplainer from PageRank nodes selection (base on #13)
# 跑完 (PubMed 沒跑)
------------------------------------------------------------
python train_remaining_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_Tree_GNNExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_tree_node_ratio_0.01 --explainer_name GNNExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_Tree_GNNExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_tree_node_ratio_0.01 --explainer_name GNNExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_Tree_GNNExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_tree_node_ratio_0.05 --explainer_name GNNExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_Tree_GNNExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_tree_node_ratio_0.05 --explainer_name GNNExplainer --node_choose top_pagerank
python train_remaining_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_Tree_GNNExplainer_PageRank --selector_type explainer --fraction 0.1 --base_dir saved/stage2_tree_node_ratio_0.05 --explainer_name GNNExplainer --node_choose top_pagerank


# 15. Generate GNNExplainer explainable subgraph from random nodes Tree(base on node regression model from #12)
# 跑完 (PubMed 沒跑完)
------------------------------------------------------------
python stage2_expsubg.py --dataset GitHub  --choose_nodes random --node_ratio 0.01 --run_mode stage2_tree_node_ratio_0.01 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset FacebookPagePage  --choose_nodes random --node_ratio 0.01 --run_mode stage2_tree_node_ratio_0.01 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset Cora  --choose_nodes random --node_ratio 0.05 --run_mode stage2_tree_node_ratio_0.05 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset CiteSeer  --choose_nodes random --node_ratio 0.05 --run_mode stage2_tree_node_ratio_0.05 --explainer_type GNNExplainer
python stage2_expsubg.py --dataset PubMed  --choose_nodes random --node_ratio 0.05 --run_mode stage2_tree_node_ratio_0.05 --explainer_type GNNExplainer


# 16. Train GNN model (node classification) after Tree + GNNExplainer from random nodes selection (base on #15)
# 跑完 (PubMed 沒跑)
------------------------------------------------------------
python train_remaining_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_Tree_GNNExplainer_random --selector_type explainer --fraction 0.1 --base_dir saved/stage2_tree_node_ratio_0.01 --explainer_name GNNExplainer --node_choose random
python train_remaining_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_Tree_GNNExplainer_random --selector_type explainer --fraction 0.1 --base_dir saved/stage2_tree_node_ratio_0.01 --explainer_name GNNExplainer --node_choose random
python train_remaining_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_Tree_GNNExplainer_random --selector_type explainer --fraction 0.1 --base_dir saved/stage2_tree_node_ratio_0.05 --explainer_name GNNExplainer --node_choose random
python train_remaining_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_Tree_GNNExplainer_random --selector_type explainer --fraction 0.1 --base_dir saved/stage2_tree_node_ratio_0.05 --explainer_name GNNExplainer --node_choose random
python train_remaining_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_GNNExplainer --note remove_edge_from_Tree_GNNExplainer_random --selector_type explainer --fraction 0.1 --base_dir saved/stage2_tree_node_ratio_0.05 --explainer_name GNNExplainer --node_choose random


# 17. Remove Edge by Random Walk (choose nodes by PageRank)
# 跑完
------------------------------------------------------------
python train_remaining_main.py --dataset GitHub --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_RandomWalk --note remove_edge_by_PageRank_RandomWalk --selector_type random_walk --fraction 0.1  --node_choose top_pagerank --node_ratio 0.05
python train_remaining_main.py --dataset FacebookPagePage --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_RandomWalk --note remove_edge_by_PageRank_RandomWalk --selector_type random_walk --fraction 0.1  --node_choose top_pagerank --node_ratio 0.05
python train_remaining_main.py --dataset Cora --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_RandomWalk --note remove_edge_by_PageRank_RandomWalk --selector_type random_walk --fraction 0.1  --node_choose top_pagerank --node_ratio 0.05
python train_remaining_main.py --dataset CiteSeer --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_RandomWalk --note remove_edge_by_PageRank_RandomWalk --selector_type random_walk --fraction 0.1  --node_choose top_pagerank --node_ratio 0.05
python train_remaining_main.py --dataset PubMed --model GCN2 --epochs 300 --lr 0.01 --run_mode remove_from_RandomWalk --note remove_edge_by_PageRank_RandomWalk --selector_type random_walk --fraction 0.1 --node_choose top_pagerank --node_ratio 0.05
